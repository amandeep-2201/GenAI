{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart with RAGStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to set up a simple RAG pipeline with RAGStack. At the end of this notebook, you will have a fully functioning Question/Answer model that can answer questions using your supplied documents.\n",
    "\n",
    "A RAG pipeline requires, at minimum, a vector store, an embedding model, and an LLM. In this tutorial, you will use an Astra DB vector store, an OpenAI embedding model, an OpenAI LLM, and LangChain to orchestrate it all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "You will need a vector-enabled Astra database and an OpenAI Account.\n",
    "\n",
    "* Create an [Astra vector database](https://docs.datastax.com/en/astra-serverless/docs/getting-started/create-db-choices.html).\n",
    "* Create an [OpenAI account](https://openai.com/)\n",
    "* Within your database, create an [Astra DB Access Token](https://docs.datastax.com/en/astra-serverless/docs/manage/org/manage-tokens.html) with Database Administrator permissions.\n",
    "* Get your Astra DB Endpoint:\n",
    "  * `https://<ASTRA_DB_ID>-<ASTRA_DB_REGION>.apps.astra.datastax.com`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "`ragstack-ai` includes all the packages you need to build a RAG pipeline.\n",
    "\n",
    "`datasets` is used to import a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ragstack-ai datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass  #used to take input from user\n",
    "\n",
    "# Enter your settings for Astra DB and OpenAI:\n",
    "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional: Check if the environment variable is loaded\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))  # Should print the key if it's loaded properly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RAG Pipeline\n",
    "\n",
    "**Embedding Model and Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astra vector store configured\n"
     ]
    }
   ],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "\n",
    "#configure your embedding model and vector store\n",
    "embedding = OpenAIEmbeddings()\n",
    "vstore = AstraDBVectorStore(\n",
    "    collection_name=\"test\",\n",
    "    embedding=embedding,\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    ")\n",
    "print(\"Astra vector store configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 574/574 [00:00<00:00, 576kB/s]\n",
      "Downloading data: 100%|██████████| 67.6k/67.6k [00:00<00:00, 149kB/s]\n",
      "Generating train split: 100%|██████████| 450/450 [00:00<00:00, 3703.83 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example entry : \n",
      "{'author': 'aristotle', 'quote': \"True happiness comes from gaining insight and growing into your best possible self. Otherwise all you're having is immediate gratification pleasure, which is fleeting and doesn't grow you as a person.\", 'tags': 'knowledge'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#load a sample datastax dataset from hugging face\n",
    "\n",
    "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]\n",
    "print(\"An example entry : \")\n",
    "print(philo_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/datastax/philosopher-quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "#Constructs a set of documents from your data. Documents can be used as inputs to your vectore store.\n",
    "docs = []\n",
    "\n",
    "#Each entry is expected to be a dictionary with keys for author, tags, and quote.\n",
    "for entry in philo_dataset:\n",
    "    metadata = {\"author\": entry[\"author\"]}\n",
    "    if entry[\"tags\"]:\n",
    "        #add metadata tags to the metadata dictionary\n",
    "        for tag in entry[\"tags\"].split(\";\"):\n",
    "            metadata[tag]= \"y\"\n",
    "    # Create a langchain document with the qoute and metadata tags\n",
    "    doc = Document(page_content = entry[\"quote\"], metadata=metadata)\n",
    "    docs.append(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'author': 'kant', 'knowledge': 'y'}, page_content='The schematicism by which our understanding deals with the phenomenal world ... is a skill so deeply hidden in the human soul that we shall hardly guess the secret trick that Nature here employs.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedddings by inserting your documents into the vector store.\n",
    "inserted_ids = vstore.add_documents(docs)\n",
    "print(f\"\\nInserted {len}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
